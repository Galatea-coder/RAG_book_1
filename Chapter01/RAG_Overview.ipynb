{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqpsYn49QWSR"
   },
   "source": [
    "#Introducing Naive, Advanced, and Modular RAG\n",
    "\n",
    "Copyright 2024, Denis Rothman\n",
    "\n",
    "This notebook introduces Naïve, Advanced, and Modular RAG through basic educational examples.\n",
    "\n",
    "The Naïve, Advanced and modular RAG techniques offer flexibility in selecting retrieval strategies, allowing adaptation to various tasks and data characteristics.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "**Part 1: Foundations and Basic Implementation**\n",
    "\n",
    "1.Environment setup for OpenAI API integration  \n",
    "2.Generator function using GPT models    \n",
    "3.Dataetup with a list of documents (db_records)  \n",
    "4.Query(user request)  \n",
    "\n",
    "**Part 2: Advanced Techniques and Evaluation**\n",
    "\n",
    "1.Retrieval metrics  \n",
    "2.Naive RAG  \n",
    "3.Advanced RAG  \n",
    "4.Modular RAG Retriever  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ICSQQ0ipxlR"
   },
   "source": [
    "# Part 1: Foundations and Basic Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o01-IM8bTc5f"
   },
   "source": [
    "# 1.The Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8VCfbN0YwHbE",
    "outputId": "7b5a9db0-3a50-4274-a428-c00599ca2644"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==1.40.3 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (1.40.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/dk/.local/lib/python3.10/site-packages (from openai==1.40.3) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from openai==1.40.3) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.40.3) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai==1.40.3) (3.10)\n",
      "Requirement already satisfied: certifi in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.40.3) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai==1.40.3) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.40.3) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.40.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai==1.40.3) (2.27.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.40.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# Scopes for Google Drive API\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "\n",
    "def authenticate_google_drive():\n",
    "    creds = None\n",
    "    # Check for previously saved credentials\n",
    "    if os.path.exists('token.pickle'):\n",
    "        with open('token.pickle', 'rb') as token:\n",
    "            creds = pickle.load(token)\n",
    "\n",
    "    # If no valid credentials, authenticate user\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for future use\n",
    "        with open('token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "\n",
    "    return build('drive', 'v3', credentials=creds)\n",
    "\n",
    "def list_files(service):\n",
    "    results = service.files().list(\n",
    "        pageSize=10, fields=\"files(id, name)\").execute()\n",
    "    items = results.get('files', [])\n",
    "    if not items:\n",
    "        print('No files found.')\n",
    "    else:\n",
    "        print('Files:')\n",
    "        for item in items:\n",
    "            print(f\"{item['name']} ({item['id']})\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    drive_service = authenticate_google_drive()\n",
    "    list_files(drive_service)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_file(service, file_id, output_path):\n",
    "    request = service.files().get_media(fileId=file_id)\n",
    "    with open(output_path, 'wb') as f:\n",
    "        f.write(request.execute())\n",
    "    print(f\"File downloaded to {output_path}\")\n",
    "\n",
    "\n",
    "file_id = \"1u4M-skJmfqO7Xp5QirzWQYu7WoExcuC4\" \n",
    "download_file(drive_service, file_id, 'api_key.txt')\n",
    "\n",
    "# Read the API key from the file\n",
    "with open('api_key.txt', 'r') as file:\n",
    "    api_key = file.read().strip()\n",
    "    OPENAI_API_KEY = api_key\n",
    "\n",
    "print(f\"API Key: {OPENAI_API_KEY}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuZ7jr4Rs36U"
   },
   "source": [
    "# 2.The Generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qwCNTW9fs36U"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "gptmodel=\"gpt-4o\"\n",
    "\n",
    "def call_llm_with_full_text(itext):\n",
    "    # Join all lines to form a single string\n",
    "    text_input = '\\n'.join(itext)\n",
    "    prompt = f\"Please elaborate on the following content:\\n{text_input}\"\n",
    "\n",
    "    try:\n",
    "      response = client.chat.completions.create(\n",
    "         model=gptmodel,\n",
    "         messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert Natural Language Processing exercise expert.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"1.You can explain read the input and answer in detail\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "         ],\n",
    "         temperature=0.1  # Add the temperature parameter here and other parameters you need\n",
    "        )\n",
    "      return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVKe9VF0HIHJ"
   },
   "source": [
    "## Formatted response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oG8I2Kb2HFhL"
   },
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def print_formatted_response(response):\n",
    "    # Define the width for wrapping the text\n",
    "    wrapper = textwrap.TextWrapper(width=80)  # Set to 80 columns wide, but adjust as needed\n",
    "    wrapped_text = wrapper.fill(text=response)\n",
    "\n",
    "    # Print the formatted response with a header and footer\n",
    "    print(\"Response:\")\n",
    "    print(\"---------------\")\n",
    "    print(wrapped_text)\n",
    "    print(\"---------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qv1ExPiZdJRL"
   },
   "source": [
    " # 3.The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "45CFxG4Fgcju"
   },
   "outputs": [],
   "source": [
    "db_records = [\n",
    "    \"Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach in the field of artificial intelligence, particularly within the realm of natural language processing (NLP).\",\n",
    "    \"It innovatively combines the capabilities of neural network-based language models with retrieval systems to enhance the generation of text, making it more accurate, informative, and contextually relevant.\",\n",
    "    \"This methodology leverages the strengths of both generative and retrieval architectures to tackle complex tasks that require not only linguistic fluency but also factual correctness and depth of knowledge.\",\n",
    "    \"At the core of Retrieval Augmented Generation (RAG) is a generative model, typically a transformer-based neural network, similar to those used in models like GPT (Generative Pre-trained Transformer) or BERT (Bidirectional Encoder Representations from Transformers).\",\n",
    "    \"This component is responsible for producing coherent and contextually appropriate language outputs based on a mixture of input prompts and additional information fetched by the retrieval component.\",\n",
    "    \"Complementing the language model is the retrieval system, which is usually built on a database of documents or a corpus of texts.\",\n",
    "    \"This system uses techniques from information retrieval to find and fetch documents that are relevant to the input query or prompt.\",\n",
    "    \"The mechanism of relevance determination can range from simple keyword matching to more complex semantic search algorithms which interpret the meaning behind the query to find the best matches.\",\n",
    "    \"This component merges the outputs from the language model and the retrieval system.\",\n",
    "    \"It effectively synthesizes the raw data fetched by the retrieval system into the generative process of the language model.\",\n",
    "    \"The integrator ensures that the information from the retrieval system is seamlessly incorporated into the final text output, enhancing the model's ability to generate responses that are not only fluent and grammatically correct but also rich in factual details and context-specific nuances.\",\n",
    "    \"When a query or prompt is received, the system first processes it to understand the requirement or the context.\",\n",
    "    \"Based on the processed query, the retrieval system searches through its database to find relevant documents or information snippets.\",\n",
    "    \"This retrieval is guided by the similarity of content in the documents to the query, which can be determined through various techniques like vector embeddings or semantic similarity measures.\",\n",
    "    \"The retrieved documents are then fed into the language model.\",\n",
    "    \"In some implementations, this integration happens at the token level, where the model can access and incorporate specific pieces of information from the retrieved texts dynamically as it generates each part of the response.\",\n",
    "    \"The language model, now augmented with direct access to retrieved information, generates a response.\",\n",
    "    \"This response is not only influenced by the training of the model but also by the specific facts and details contained in the retrieved documents, making it more tailored and accurate.\",\n",
    "    \"By directly incorporating information from external sources, Retrieval Augmented Generation (RAG) models can produce responses that are more factual and relevant to the given query.\",\n",
    "    \"This is particularly useful in domains like medical advice, technical support, and other areas where precision and up-to-date knowledge are crucial.\",\n",
    "    \"Retrieval Augmented Generation (RAG) systems can dynamically adapt to new information since they retrieve data in real-time from their databases.\",\n",
    "    \"This allows them to remain current with the latest knowledge and trends without needing frequent retraining.\",\n",
    "    \"With access to a wide range of documents, Retrieval Augmented Generation (RAG) systems can provide detailed and nuanced answers that a standalone language model might not be capable of generating based solely on its pre-trained knowledge.\",\n",
    "    \"While Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes with its challenges.\",\n",
    "    \"These include the complexity of integrating retrieval and generation systems, the computational overhead associated with real-time data retrieval, and the need for maintaining a large, up-to-date, and high-quality database of retrievable texts.\",\n",
    "    \"Furthermore, ensuring the relevance and accuracy of the retrieved information remains a significant challenge, as does managing the potential for introducing biases or errors from the external sources.\",\n",
    "    \"In summary, Retrieval Augmented Generation represents a significant advancement in the field of artificial intelligence, merging the best of retrieval-based and generative technologies to create systems that not only understand and generate natural language but also deeply comprehend and utilize the vast amounts of information available in textual form.\",\n",
    "    \"A RAG vector store is a database or dataset that contains vectorized data points.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIQ7NK92g7EC",
    "outputId": "3068525a-874b-4554-b5a5-2b2f270d3957"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Augmented Generation (RAG) represents a sophisticated hybrid approach\n",
      "in the field of artificial intelligence, particularly within the realm of\n",
      "natural language processing (NLP). It innovatively combines the capabilities of\n",
      "neural network-based language models with retrieval systems to enhance the\n",
      "generation of text, making it more accurate, informative, and contextually\n",
      "relevant. This methodology leverages the strengths of both generative and\n",
      "retrieval architectures to tackle complex tasks that require not only linguistic\n",
      "fluency but also factual correctness and depth of knowledge. At the core of\n",
      "Retrieval Augmented Generation (RAG) is a generative model, typically a\n",
      "transformer-based neural network, similar to those used in models like GPT\n",
      "(Generative Pre-trained Transformer) or BERT (Bidirectional Encoder\n",
      "Representations from Transformers). This component is responsible for producing\n",
      "coherent and contextually appropriate language outputs based on a mixture of\n",
      "input prompts and additional information fetched by the retrieval component.\n",
      "Complementing the language model is the retrieval system, which is usually built\n",
      "on a database of documents or a corpus of texts. This system uses techniques\n",
      "from information retrieval to find and fetch documents that are relevant to the\n",
      "input query or prompt. The mechanism of relevance determination can range from\n",
      "simple keyword matching to more complex semantic search algorithms which\n",
      "interpret the meaning behind the query to find the best matches. This component\n",
      "merges the outputs from the language model and the retrieval system. It\n",
      "effectively synthesizes the raw data fetched by the retrieval system into the\n",
      "generative process of the language model. The integrator ensures that the\n",
      "information from the retrieval system is seamlessly incorporated into the final\n",
      "text output, enhancing the model's ability to generate responses that are not\n",
      "only fluent and grammatically correct but also rich in factual details and\n",
      "context-specific nuances. When a query or prompt is received, the system first\n",
      "processes it to understand the requirement or the context. Based on the\n",
      "processed query, the retrieval system searches through its database to find\n",
      "relevant documents or information snippets. This retrieval is guided by the\n",
      "similarity of content in the documents to the query, which can be determined\n",
      "through various techniques like vector embeddings or semantic similarity\n",
      "measures. The retrieved documents are then fed into the language model. In some\n",
      "implementations, this integration happens at the token level, where the model\n",
      "can access and incorporate specific pieces of information from the retrieved\n",
      "texts dynamically as it generates each part of the response. The language model,\n",
      "now augmented with direct access to retrieved information, generates a response.\n",
      "This response is not only influenced by the training of the model but also by\n",
      "the specific facts and details contained in the retrieved documents, making it\n",
      "more tailored and accurate. By directly incorporating information from external\n",
      "sources, Retrieval Augmented Generation (RAG) models can produce responses that\n",
      "are more factual and relevant to the given query. This is particularly useful in\n",
      "domains like medical advice, technical support, and other areas where precision\n",
      "and up-to-date knowledge are crucial. Retrieval Augmented Generation (RAG)\n",
      "systems can dynamically adapt to new information since they retrieve data in\n",
      "real-time from their databases. This allows them to remain current with the\n",
      "latest knowledge and trends without needing frequent retraining. With access to\n",
      "a wide range of documents, Retrieval Augmented Generation (RAG) systems can\n",
      "provide detailed and nuanced answers that a standalone language model might not\n",
      "be capable of generating based solely on its pre-trained knowledge. While\n",
      "Retrieval Augmented Generation (RAG) offers substantial benefits, it also comes\n",
      "with its challenges. These include the complexity of integrating retrieval and\n",
      "generation systems, the computational overhead associated with real-time data\n",
      "retrieval, and the need for maintaining a large, up-to-date, and high-quality\n",
      "database of retrievable texts. Furthermore, ensuring the relevance and accuracy\n",
      "of the retrieved information remains a significant challenge, as does managing\n",
      "the potential for introducing biases or errors from the external sources. In\n",
      "summary, Retrieval Augmented Generation represents a significant advancement in\n",
      "the field of artificial intelligence, merging the best of retrieval-based and\n",
      "generative technologies to create systems that not only understand and generate\n",
      "natural language but also deeply comprehend and utilize the vast amounts of\n",
      "information available in textual form. A RAG vector store is a database or\n",
      "dataset that contains vectorized data points.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "paragraph = ' '.join(db_records)\n",
    "wrapped_text = textwrap.fill(paragraph, width=80)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aL7cHuuLhQ5w"
   },
   "source": [
    "# 4.The Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qARk6gtohSXW"
   },
   "outputs": [],
   "source": [
    "query = \"define a rag store\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iITo3QIF7yeK"
   },
   "source": [
    "Generation without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXBILWI47yeM",
    "outputId": "d262bd68-fb4c-4d59-a51b-5a3f60e54e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "Certainly! The content you've provided seems to be a request to define the term\n",
      "\"arag store.\" However, it appears there might be a typo or misunderstanding, as\n",
      "\"arag store\" is not a commonly recognized term in English. It's possible that\n",
      "you meant \"arg store\" or another similar term.   Let's explore a few\n",
      "possibilities:  1. **Arg Store**: If you meant \"arg store,\" it could refer to a\n",
      "storage system or method for handling arguments in programming. In many\n",
      "programming languages, \"args\" is short for \"arguments,\" which are values or\n",
      "variables passed to functions or programs. An \"arg store\" might be a conceptual\n",
      "or physical place where these arguments are stored for processing.  2. **A Rag\n",
      "Store**: If you meant \"a rag store,\" it could refer to a store that sells rags\n",
      "or cloth materials. These stores might supply cleaning rags, fabric remnants, or\n",
      "other textile products.  3. **Arag Store**: If \"arag store\" is indeed the\n",
      "correct term, it might be a specific brand, business, or concept not widely\n",
      "recognized. In this case, more context would be needed to provide an accurate\n",
      "definition.  If you have more context or if there's a specific area (such as\n",
      "technology, retail, etc.) you're referring to, please provide additional details\n",
      "so I can offer a more precise explanation.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print the result\n",
    "llm_response = call_llm_with_full_text(query)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11HLkKQMqaDt"
   },
   "source": [
    "# Part 2: Advanced Techniques and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMGuZg1WiaUE"
   },
   "source": [
    "# 1.Retrieval Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KHN6s7wZirQL"
   },
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_GLECrTQirQN"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_cosine_similarity(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words='english',\n",
    "        use_idf=True,\n",
    "        norm='l2',\n",
    "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
    "        sublinear_tf=True,   # Apply sublinear TF scaling\n",
    "        analyzer='word'      # You could also experiment with 'char' or 'char_wb' for character-level features\n",
    "    )\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    similarity = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (1.0.11)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (8.3.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (2.5.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/dk/.local/lib/python3.10/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dk/.local/lib/python3.10/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/dk/.local/lib/python3.10/site-packages (from spacy) (2.1.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dk/.local/lib/python3.10/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (2.10.4)\n",
      "Requirement already satisfied: jinja2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dk/.local/lib/python3.10/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dk/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dk/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.12.14)\n",
      "Requirement already satisfied: blis<1.2.0,>=1.1.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/dk/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/dk/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/dk/.local/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/dk/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/dk/.local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/dk/miniconda3/envs/rag1/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/dk/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Requirement already satisfied: nltk in /home/dk/.local/lib/python3.10/site-packages (3.9)\n",
      "Requirement already satisfied: click in /home/dk/.local/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/dk/.local/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/dk/.local/lib/python3.10/site-packages (from nltk) (2024.7.24)\n",
      "Requirement already satisfied: tqdm in /home/dk/.local/lib/python3.10/site-packages (from nltk) (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy\n",
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTJOi-jrjI5A"
   },
   "source": [
    "## Enhanced Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnmPG9UWjJXD",
    "outputId": "14129a2a-9e7b-47bb-d88e-a8c70ab50ae7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name())\n",
    "    return synonyms\n",
    "\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmatized_words = []\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue\n",
    "        lemmatized_words.append(token.lemma_)\n",
    "    return lemmatized_words\n",
    "\n",
    "def expand_with_synonyms(words):\n",
    "    expanded_words = words.copy()\n",
    "    for word in words:\n",
    "        expanded_words.extend(get_synonyms(word))\n",
    "    return expanded_words\n",
    "\n",
    "def calculate_enhanced_similarity(text1, text2):\n",
    "    # Preprocess and tokenize texts\n",
    "    words1 = preprocess_text(text1)\n",
    "    words2 = preprocess_text(text2)\n",
    "\n",
    "    # Expand with synonyms\n",
    "    words1_expanded = expand_with_synonyms(words1)\n",
    "    words2_expanded = expand_with_synonyms(words2)\n",
    "\n",
    "    # Count word frequencies\n",
    "    freq1 = Counter(words1_expanded)\n",
    "    freq2 = Counter(words2_expanded)\n",
    "\n",
    "    # Create a set of all unique words\n",
    "    unique_words = set(freq1.keys()).union(set(freq2.keys()))\n",
    "\n",
    "    # Create frequency vectors\n",
    "    vector1 = [freq1[word] for word in unique_words]\n",
    "    vector2 = [freq2[word] for word in unique_words]\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    vector1 = np.array(vector1)\n",
    "    vector2 = np.array(vector2)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFqh9rr81SUn"
   },
   "source": [
    "# 2.Naive RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wu8vteKmS_qO"
   },
   "source": [
    "## Keyword search and matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WY1JU0Ush_l4",
    "outputId": "a20e6e9b-f91d-4f4f-8962-0f7611fd51d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Keyword Score: 3\n",
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def find_best_match_keyword_search(query, db_records):\n",
    "    best_score = 0\n",
    "    best_record = None\n",
    "\n",
    "    # Split the query into individual keywords\n",
    "    query_keywords = set(query.lower().split())\n",
    "\n",
    "    # Iterate through each record in db_records\n",
    "    for record in db_records:\n",
    "        # Split the record into keywords\n",
    "        record_keywords = set(record.lower().split())\n",
    "\n",
    "        # Calculate the number of common keywords\n",
    "        common_keywords = query_keywords.intersection(record_keywords)\n",
    "        current_score = len(common_keywords)\n",
    "\n",
    "        # Update the best score and record if the current score is higher\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_record = record\n",
    "\n",
    "    return best_score, best_record\n",
    "\n",
    "# Assuming 'query' and 'db_records' are defined in previous cells in your Colab notebook\n",
    "best_keyword_score, best_matching_record = find_best_match_keyword_search(query, db_records)\n",
    "\n",
    "print(f\"Best Keyword Score: {best_keyword_score}\")\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oak-3k_dkzC3"
   },
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blcPOIaHkzC4",
    "outputId": "0352d9e2-73e7-4aba-eb91-13d80cd820c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.126\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity\n",
    "score = calculate_cosine_similarity(query, best_matching_record)\n",
    "print(f\"Best Cosine Similarity Score: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OW0l24IkzC5",
    "outputId": "009b16b0-5f38-42d9-ad08-db130568276e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity:, 0.642\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Similarity\n",
    "response = best_matching_record\n",
    "print(query,\": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, response)\n",
    "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2zKQhiO0Fcr"
   },
   "source": [
    "## Augmented input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "r_7ymSxG0Fcs"
   },
   "outputs": [],
   "source": [
    "augmented_input=query+ \": \"+ best_matching_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NTfxzum0PT2",
    "outputId": "3d8a0bd9-33bb-44da-8b99-38982adeabc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "define a rag store: A RAG vector store is a database or dataset that contains\n",
      "vectorized data points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ui8wH4k3_g4"
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jh8BsnUy0Fcs",
    "outputId": "fbd0790d-0fd6-4648-c2c3-0a3a6b077d27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "A vector store, often referred to as a vector database or vector dataset, is a\n",
      "specialized type of data storage system designed to handle and manage vectorized\n",
      "data points. These data points are typically represented as vectors, which are\n",
      "mathematical entities that have both magnitude and direction. In the context of\n",
      "data storage, vectors are often used to represent complex data in a simplified\n",
      "numerical form, making it easier to perform various computational tasks such as\n",
      "similarity searches, clustering, and machine learning.  Here are some key\n",
      "aspects of a vector store:  1. **Vector Representation**: In a vector store,\n",
      "each data point is represented as a vector. This means that the data is\n",
      "transformed into a numerical format, often as a list or array of numbers. This\n",
      "transformation is crucial for enabling efficient mathematical operations and\n",
      "comparisons.  2. **Applications**: Vector stores are widely used in applications\n",
      "that require handling large volumes of high-dimensional data. Common use cases\n",
      "include recommendation systems, natural language processing (NLP), image\n",
      "recognition, and other machine learning tasks where data needs to be compared or\n",
      "clustered based on similarity.  3. **Similarity Search**: One of the primary\n",
      "functions of a vector store is to facilitate similarity searches. This involves\n",
      "finding vectors that are similar to a given query vector. Techniques such as\n",
      "nearest neighbor search are employed to efficiently retrieve similar data\n",
      "points, which is essential for applications like search engines and\n",
      "recommendation systems.  4. **Scalability**: Vector stores are designed to\n",
      "handle large datasets efficiently. They often include indexing mechanisms and\n",
      "optimized data structures to ensure quick retrieval and processing of vectors,\n",
      "even as the dataset grows in size.  5. **Integration with Machine Learning**:\n",
      "Vector stores are integral to many machine learning workflows. They provide a\n",
      "structured way to store and retrieve feature vectors, which are used as inputs\n",
      "for machine learning models. This integration helps in training, evaluating, and\n",
      "deploying models effectively.  6. **Data Transformation**: Before data can be\n",
      "stored in a vector store, it often needs to be transformed into a vector format.\n",
      "This process, known as vectorization, involves converting raw data (such as\n",
      "text, images, or audio) into a numerical representation that captures the\n",
      "essential features of the data.  In summary, a vector store is a powerful tool\n",
      "for managing and utilizing vectorized data, enabling efficient data retrieval\n",
      "and processing in various computational and machine learning applications.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print the result\n",
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJH2__0iTUr1"
   },
   "source": [
    "# 3.Advanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awyjcn35jFiy"
   },
   "source": [
    "## 3.1.Vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kD8_758kkq3h"
   },
   "source": [
    "### Search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FCBbY4qLc8qh"
   },
   "outputs": [],
   "source": [
    "def find_best_match(text_input, records):\n",
    "    best_score = 0\n",
    "    best_record = None\n",
    "    for record in records:\n",
    "        current_score = calculate_cosine_similarity(text_input, record)\n",
    "        if current_score > best_score:\n",
    "            best_score = current_score\n",
    "            best_record = record\n",
    "    return best_score, best_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RG1iM-U33OCg"
   },
   "outputs": [],
   "source": [
    "best_similarity_score, best_matching_record = find_best_match(query, db_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PLa9NQ4Cm_YQ",
    "outputId": "7aac4922-3c63-48a0-afa4-32580bedbc5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A60QoOA3jf9j"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIUh-38knHLI",
    "outputId": "11f8eeb6-7cd3-40bc-c6ad-fe03332f5f7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.126\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQopW_FSjBSr",
    "outputId": "75cef793-36ee-4dee-ca1a-6d41844654b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity:, 0.642\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Similarity\n",
    "response = best_matching_record\n",
    "print(query,\": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, best_matching_record)\n",
    "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51fZC6Oe2G9E"
   },
   "source": [
    "### Augmented input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "4dcnK7OGx5e6"
   },
   "outputs": [],
   "source": [
    "augmented_input=query+\": \"+best_matching_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3uk-91x049J",
    "outputId": "81eed858-e9f5-45ef-e603-1c9374490398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "define a rag store: A RAG vector store is a database or dataset that contains\n",
      "vectorized data points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFDF6hbi2LF9"
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YJC-mA5ftxFU",
    "outputId": "1358b6e7-da69-45b5-b22d-818f489be893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "An \"ARAG vector store\" refers to a specialized type of database or dataset\n",
      "designed to store and manage vectorized data points. Let's break down the\n",
      "concept further:  1. **Vectorized Data Points**: In the context of data science\n",
      "and machine learning, data is often transformed into vectors, which are arrays\n",
      "of numbers. These vectors can represent various types of data, such as text,\n",
      "images, or any other form of information that can be numerically encoded. For\n",
      "example, in natural language processing, words or sentences can be converted\n",
      "into vectors using techniques like word embeddings (e.g., Word2Vec, GloVe) or\n",
      "sentence embeddings.  2. **Purpose of a Vector Store**: The primary purpose of a\n",
      "vector store is to efficiently store, retrieve, and manage these vectorized\n",
      "representations. This is crucial for tasks that involve similarity search,\n",
      "clustering, or any operation that requires comparing or analyzing high-\n",
      "dimensional data.  3. **Applications**: Vector stores are commonly used in\n",
      "applications such as recommendation systems, search engines, and machine\n",
      "learning pipelines. For instance, in a recommendation system, user preferences\n",
      "and item features can be represented as vectors, and the system can quickly find\n",
      "similar items or users by comparing these vectors.  4. **Efficiency and\n",
      "Scalability**: A well-designed vector store is optimized for handling large\n",
      "volumes of high-dimensional data. It often includes indexing mechanisms to speed\n",
      "up similarity searches and reduce computational overhead. This is important for\n",
      "applications that need to process data in real-time or handle large datasets.\n",
      "5. **Examples**: There are several tools and frameworks available for creating\n",
      "and managing vector stores, such as FAISS (Facebook AI Similarity Search), Annoy\n",
      "(Approximate Nearest Neighbors Oh Yeah), and Elasticsearch with vector\n",
      "capabilities.  In summary, an ARAG vector store is a crucial component in\n",
      "systems that require efficient handling of vectorized data, enabling advanced\n",
      "data analysis and retrieval tasks.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print the result\n",
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7djpPBpm0M2"
   },
   "source": [
    "## 3.2.Index-based search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyDUhy_1lBfT"
   },
   "source": [
    "### Search Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRarT_fym2XC",
    "outputId": "9504537f-2354-48bd-de30-f5b4d48b789f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def setup_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(records)\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "def find_best_match(query, vectorizer, tfidf_matrix):\n",
    "    query_tfidf = vectorizer.transform([query])\n",
    "    similarities = cosine_similarity(query_tfidf, tfidf_matrix)\n",
    "    best_index = similarities.argmax()  # Get the index of the highest similarity score\n",
    "    best_score = similarities[0, best_index]\n",
    "    return best_score, best_index\n",
    "\n",
    "vectorizer, tfidf_matrix = setup_vectorizer(db_records)\n",
    "\n",
    "best_similarity_score, best_index = find_best_match(query, vectorizer, tfidf_matrix)\n",
    "best_matching_record = db_records[best_index]\n",
    "\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt3iBtJFj4sa"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UoNUQqx5j3r4",
    "outputId": "96893316-9ce5-4a2b-9706-20bef4cf1e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.407\n",
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity\n",
    "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vg910Mhuj3sO",
    "outputId": "262b207e-5ecb-4441-fc15-656cbd0a7ffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity:, 0.642\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Similarity\n",
    "response = best_matching_record\n",
    "print(query,\": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, response)\n",
    "print(f\"Enhanced Similarity:, {similarity_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubm0DTxKeqR9"
   },
   "source": [
    "Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SbokQ2eacHjM",
    "outputId": "52a1e0f4-ff6c-44ed-8d45-8f1153fc8c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ability    access  accuracy  accurate     adapt  additional  advancement  \\\n",
      "0   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "1   0.000000  0.000000  0.000000  0.216364  0.000000    0.000000     0.000000   \n",
      "2   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "3   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "4   0.000000  0.000000  0.000000  0.000000  0.000000    0.236479     0.000000   \n",
      "5   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "6   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "7   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "8   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "9   0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "10  0.186734  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "11  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "12  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "13  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "14  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "15  0.000000  0.172624  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "16  0.000000  0.317970  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "17  0.000000  0.000000  0.000000  0.206861  0.000000    0.000000     0.000000   \n",
      "18  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "19  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "20  0.000000  0.000000  0.000000  0.000000  0.275802    0.000000     0.000000   \n",
      "21  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "22  0.000000  0.174772  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "23  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "24  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "25  0.000000  0.000000  0.228743  0.000000  0.000000    0.000000     0.000000   \n",
      "26  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.173327   \n",
      "27  0.000000  0.000000  0.000000  0.000000  0.000000    0.000000     0.000000   \n",
      "\n",
      "      advice  algorithms    allows  ...    vector  vectorized      when  \\\n",
      "0   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "1   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "2   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "3   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "4   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "5   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "6   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "7   0.000000    0.220687  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "8   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "9   0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "10  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "11  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.295573   \n",
      "12  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "13  0.000000    0.000000  0.000000  ...  0.200131     0.00000  0.000000   \n",
      "14  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "15  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "16  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "17  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "18  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "19  0.244401    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "20  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "21  0.000000    0.000000  0.291503  ...  0.000000     0.00000  0.000000   \n",
      "22  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "23  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "24  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "25  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "26  0.000000    0.000000  0.000000  ...  0.000000     0.00000  0.000000   \n",
      "27  0.000000    0.000000  0.000000  ...  0.307719     0.34589  0.000000   \n",
      "\n",
      "       where     which    while     wide      with    within   without  \n",
      "0   0.000000  0.000000  0.00000  0.00000  0.000000  0.260582  0.000000  \n",
      "1   0.000000  0.000000  0.00000  0.00000  0.160278  0.000000  0.000000  \n",
      "2   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "3   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "4   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "5   0.000000  0.247710  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "6   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "7   0.000000  0.179053  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "8   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "9   0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "10  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "11  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "12  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "13  0.000000  0.182517  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "14  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "15  0.189283  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "16  0.000000  0.000000  0.00000  0.00000  0.258278  0.000000  0.000000  \n",
      "17  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "18  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "19  0.217430  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "20  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "21  0.000000  0.000000  0.00000  0.00000  0.192110  0.000000  0.291503  \n",
      "22  0.000000  0.000000  0.00000  0.21541  0.141963  0.000000  0.000000  \n",
      "23  0.000000  0.000000  0.32932  0.00000  0.217033  0.000000  0.000000  \n",
      "24  0.000000  0.000000  0.00000  0.00000  0.134513  0.000000  0.000000  \n",
      "25  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "26  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "27  0.000000  0.000000  0.00000  0.00000  0.000000  0.000000  0.000000  \n",
      "\n",
      "[28 rows x 297 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def setup_vectorizer(records):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(records)\n",
    "\n",
    "    # Convert the TF-IDF matrix to a DataFrame for display purposes\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "    # Display the DataFrame\n",
    "    print(tfidf_df)\n",
    "\n",
    "    return vectorizer, tfidf_matrix\n",
    "\n",
    "vectorizer, tfidf_matrix = setup_vectorizer(db_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dABZ12Bkugtt"
   },
   "source": [
    "### Augmented input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "1w4wppuA4eNn"
   },
   "outputs": [],
   "source": [
    "augmented_input=query+\": \"+best_matching_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MNozI65K4e7u",
    "outputId": "9a909e7f-bd6d-450c-dd2c-a96b8ec4ad62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "define a rag store: A RAG vector store is a database or dataset that contains\n",
      "vectorized data points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hU998zkD4hpD"
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uy9X-l_Iugtt",
    "outputId": "508c8c2c-e2a6-48fe-bfb0-ccd4add39e74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "An \"ARAG vector store\" refers to a type of database or dataset specifically\n",
      "designed to store and manage vectorized data points. Let's break down the\n",
      "concept further:  1. **Vectorized Data Points**: In the context of data storage\n",
      "and processing, vectorization refers to the process of converting data into a\n",
      "numerical format that can be easily processed by machine learning algorithms.\n",
      "Each data point is represented as a vector, which is essentially an array of\n",
      "numbers. These vectors can represent various types of data, such as text,\n",
      "images, or any other form of information that can be encoded numerically.  2.\n",
      "**Purpose of a Vector Store**: The primary purpose of a vector store is to\n",
      "efficiently store and retrieve these vectorized data points. This is\n",
      "particularly useful in applications involving machine learning, data analysis,\n",
      "and artificial intelligence, where large volumes of data need to be processed\n",
      "quickly and accurately.  3. **Applications**: Vector stores are commonly used in\n",
      "scenarios such as:    - **Similarity Search**: Finding data points that are\n",
      "similar to a given query vector. This is useful in recommendation systems, image\n",
      "recognition, and natural language processing.    - **Clustering**: Grouping\n",
      "similar data points together based on their vector representations.    -\n",
      "**Classification**: Assigning labels to data points based on their vector\n",
      "characteristics.  4. **Benefits**: Using a vector store allows for:    -\n",
      "**Efficient Data Retrieval**: Fast access to data points based on their vector\n",
      "properties.    - **Scalability**: Ability to handle large datasets with high-\n",
      "dimensional vectors.    - **Flexibility**: Support for various types of data and\n",
      "machine learning models.  In summary, an ARAG vector store is a specialized\n",
      "database designed to handle vectorized data, enabling efficient storage,\n",
      "retrieval, and processing of data points for various machine learning and data\n",
      "analysis tasks.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print the result\n",
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWEvzcDHTX6i"
   },
   "source": [
    "# 4.Modular RAG\n",
    "\n",
    "Modular RAG can combine methods. For example:\n",
    "\n",
    "**keyword search**:Searches through each document to find the one that best matches the keyword(s).\n",
    "\n",
    "**vector search**: Searches through each document and calculates similarity.\n",
    "\n",
    "**indexed search**: Uses a precomputed index (TF-IDF matrix) to compute cosine similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sv-VqmLf3EQ9"
   },
   "source": [
    "**October 25, 2025 update**\n",
    "\n",
    "`self.documents` is initialized in the fit method to hold the records used for searching and enable the `keyword_search` function to access them without error.\n",
    "\n",
    "**Note on Vector search**\n",
    "\n",
    "In this case, the `def vector_search(self, query):` uses `tfidf_matrix`to increase the vector search performance.\n",
    "\n",
    "The `def vector_search(self, query):` function could use a brute-force method as implemented in `Section 3.1.Vector search` of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "18wmqwJd4o62"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class RetrievalComponent:\n",
    "    def __init__(self, method='vector'):\n",
    "        self.method = method\n",
    "        if self.method == 'vector' or self.method == 'indexed':\n",
    "            self.vectorizer = TfidfVectorizer()\n",
    "            self.tfidf_matrix = None\n",
    "\n",
    "    def fit(self, records):\n",
    "      self.documents = records  # Initialize self.documents here\n",
    "      if self.method == 'vector' or self.method == 'indexed':\n",
    "        self.tfidf_matrix = self.vectorizer.fit_transform(records)\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        if self.method == 'keyword':\n",
    "            return self.keyword_search(query)\n",
    "        elif self.method == 'vector':\n",
    "            return self.vector_search(query)\n",
    "        elif self.method == 'indexed':\n",
    "            return self.indexed_search(query)\n",
    "\n",
    "    def keyword_search(self, query):\n",
    "        best_score = 0\n",
    "        best_record = None\n",
    "        query_keywords = set(query.lower().split())\n",
    "        for index, doc in enumerate(self.documents):\n",
    "            doc_keywords = set(doc.lower().split())\n",
    "            common_keywords = query_keywords.intersection(doc_keywords)\n",
    "            score = len(common_keywords)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_record = self.documents[index]\n",
    "        return best_record\n",
    "\n",
    "    def vector_search(self, query):\n",
    "        query_tfidf = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
    "        best_index = similarities.argmax()\n",
    "        return db_records[best_index]\n",
    "\n",
    "    def indexed_search(self, query):\n",
    "        # Assuming the tfidf_matrix is precomputed and stored\n",
    "        query_tfidf = self.vectorizer.transform([query])\n",
    "        similarities = cosine_similarity(query_tfidf, self.tfidf_matrix)\n",
    "        best_index = similarities.argmax()\n",
    "        return db_records[best_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qHm4saJ8cGk"
   },
   "source": [
    "### Modular RAG Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_kvhIOdY8amp",
    "outputId": "c0a631da-db68-4023-d7b1-dff0586c1dab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "retrieval = RetrievalComponent(method='vector')  # Choose from 'keyword', 'vector', 'indexed'\n",
    "retrieval.fit(db_records)\n",
    "best_matching_record = retrieval.retrieve(query)\n",
    "\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DgxXdqzvkYDk"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "COyYme4IkYDx",
    "outputId": "f6fda5ac-021c-4d98-fe61-b58b5d356dbc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cosine Similarity Score: 0.407\n",
      "Response:\n",
      "---------------\n",
      "A RAG vector store is a database or dataset that contains vectorized data\n",
      "points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity\n",
    "print(f\"Best Cosine Similarity Score: {best_similarity_score:.3f}\")\n",
    "print_formatted_response(best_matching_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YRTpIpzkYDx",
    "outputId": "f35ce40d-5b4e-4917-a9c1-1305df3cc800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "define a rag store :  A RAG vector store is a database or dataset that contains vectorized data points.\n",
      "Enhanced Similarity: 0.641582812483307\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Similarity\n",
    "response = best_matching_record\n",
    "print(query,\": \", response)\n",
    "similarity_score = calculate_enhanced_similarity(query, response)\n",
    "print(\"Enhanced Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TaQa7Dc7JwT"
   },
   "source": [
    "### Augmented Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "X-hKjhIU7Jwg"
   },
   "outputs": [],
   "source": [
    "augmented_input=query+ \" \"+ best_matching_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhSO-fyZ7Jwg",
    "outputId": "3e17c370-ab59-4ce6-9829-45abe3aff659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "define a rag store A RAG vector store is a database or dataset that contains\n",
      "vectorized data points.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_formatted_response(augmented_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkyYx_MC7Jwg"
   },
   "source": [
    "### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-V3srRHW7Jwh",
    "outputId": "4ebad0d9-0b9e-4ef2-883d-e69fc57b2363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "---------------\n",
      "Certainly! Let's break down the concept of a \"vector store\" or \"vector database\"\n",
      "and understand what it means in the context of data storage and retrieval.  ###\n",
      "What is a Vector Store?  A **vector store** or **vector database** is a\n",
      "specialized type of database or dataset designed to store and manage data in the\n",
      "form of vectors. Vectors are mathematical representations of data points, often\n",
      "used in machine learning and data science to represent features or\n",
      "characteristics of data in a numerical format.  ### Key Characteristics of a\n",
      "Vector Store:  1. **Vectorized Data Points**:     - The primary feature of a\n",
      "vector store is that it contains data points that have been transformed into\n",
      "vectors. Each vector is typically a list or array of numbers that represent\n",
      "various attributes or features of the data point.  2. **High-Dimensional Data**:\n",
      "- Vectors can be of high dimensionality, meaning they can have a large number of\n",
      "elements. This is common in applications like image processing, natural language\n",
      "processing, and recommendation systems, where each data point might be\n",
      "represented by hundreds or thousands of features.  3. **Efficient Similarity\n",
      "Search**:    - One of the main uses of vector stores is to perform similarity\n",
      "searches efficiently. This involves finding vectors that are similar to a given\n",
      "query vector, which is crucial in applications like nearest neighbor search,\n",
      "clustering, and anomaly detection.  4. **Scalability**:    - Vector stores are\n",
      "designed to handle large volumes of data and support fast retrieval times, even\n",
      "as the dataset grows. This is important for real-time applications and large-\n",
      "scale machine learning tasks.  5. **Integration with Machine Learning**:    -\n",
      "Vector stores are often integrated with machine learning models. For example,\n",
      "embeddings generated by neural networks (such as word embeddings or image\n",
      "embeddings) are stored as vectors in these databases for further analysis and\n",
      "retrieval.  ### Applications of Vector Stores:  - **Recommendation Systems**:\n",
      "Vector stores are used to store user and item embeddings, allowing for efficient\n",
      "computation of recommendations based on similarity. - **Natural Language\n",
      "Processing**: Word embeddings or sentence embeddings are stored as vectors to\n",
      "facilitate tasks like semantic search and text classification. - **Image and\n",
      "Video Processing**: Feature vectors extracted from images or videos are stored\n",
      "for tasks like image retrieval and object recognition. - **Anomaly Detection**:\n",
      "Vectors representing normal behavior patterns are stored, and deviations from\n",
      "these patterns can be detected as anomalies.  ### Examples of Vector Stores:  -\n",
      "**FAISS (Facebook AI Similarity Search)**: A library for efficient similarity\n",
      "search and clustering of dense vectors. - **Annoy (Approximate Nearest Neighbors\n",
      "Oh Yeah)**: A C++ library with Python bindings for searching nearest neighbors.\n",
      "- **Milvus**: An open-source vector database designed for AI applications,\n",
      "supporting high-dimensional vector similarity search.  In summary, a vector\n",
      "store is a powerful tool for managing and retrieving vectorized data, enabling\n",
      "efficient similarity searches and supporting various machine learning and data\n",
      "science applications.\n",
      "---------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the function and print the result\n",
    "llm_response = call_llm_with_full_text(augmented_input)\n",
    "print_formatted_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rag1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
